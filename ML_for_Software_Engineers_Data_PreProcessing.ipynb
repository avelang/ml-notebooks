{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ML for Software Engineers : Data PreProcessing.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "jtam8mVzSnxG"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XFGF8hbj-ba2",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kzcL3FKw5Ipl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import sklearn\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UNHlqSs_TmNA",
        "colab_type": "text"
      },
      "source": [
        "# Data Pre-processing with sci-kit learn"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "31Z6Vu69rRfX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "data = np.array([\n",
        "  [5.1, 3.5, 1.4, 0.2],\n",
        "  [4.9, 3. , 1.4, 0.2],\n",
        "  [4.7, 3.2, 1.3, 0.2],\n",
        "  [4.6, 3.1, 1.5, 0.2],\n",
        "  [5. , 3.6, 1.4, 0.2],\n",
        "  [5.4, 3.9, 1.7, 0.4],\n",
        "  [4.6, 3.4, 1.4, 0.3],\n",
        "  [5. , 3.4, 1.5, 0.2],\n",
        "  [4.4, 2.9, 1.4, 0.2],\n",
        "  [4.9, 3.1, 1.5, 0.1]])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rbBKUQWMU_ZJ",
        "colab_type": "text"
      },
      "source": [
        "# Scaling Data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SEGdfZCFYLI3",
        "colab_type": "text"
      },
      "source": [
        "> **Scaling data**\n",
        "This means reducing its range. There are multiple ways to do this\n",
        "*   Standardization : Reducing data to a standard format i.e. Mean=0; Std=1. (using scale())\n",
        "*   Range Scaling : Scaling the data to be within a specific range (using MinMaxScaler())\n",
        "*   Robust Scaling : Dealing with outliers in data that would otherwise skew the distribution (using a RobustScalar())\n",
        "*   Normalization : L2 Normalizing rows, using Normalizer()\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CSJvNYiILYJf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.preprocessing import scale\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.preprocessing import RobustScaler\n",
        "from sklearn.preprocessing import Normalizer"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ge-dcYL7OKUX",
        "colab_type": "text"
      },
      "source": [
        "# Data Imputation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "70sZqyW_PmNb",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hmOU78tdOO-q",
        "colab_type": "text"
      },
      "source": [
        "Substituting missing values with other values. Different ways to do data imputation are as follows"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eGJlh8bBOVFE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.impute import SimpleImputer # Use SimpleImputer transform/function from the impute module\n",
        "\n",
        "imp_mean = SimpleImputer() # by default the mean of the values is used\n",
        "imp_median = SimpleImputer(strategy='median') # use median\n",
        "imp_frequent = SimpleImputer(strategy='most_frequent') # use the most frequently used value\n",
        "imp_constat = SimpleImputer(strategy='constant', fill_value=1) # use a constant value"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jtam8mVzSnxG",
        "colab_type": "text"
      },
      "source": [
        "# Dimensionality Reduction"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1tCh-e8CS1vy",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "\n",
        "*   *Dimensionality Reduction* - Reducing the number of columns in the data array.\n",
        "*   *principal components* of the dataset  - an uncorrelated set of latent variables that encompass most of the information from the original dataset.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GpPlGC-UUc6A",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.decomposition import PCA\n",
        "  pca_obj = PCA(n_components=3)\n",
        "  component_data = pca_obj.fit_transform(data)"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}